{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "al47Jt3wF7s6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Theoretical"
      ],
      "metadata": {
        "id": "Wqoy_w6_GIWK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "623e33b1"
      },
      "source": [
        "\n",
        "\n",
        "1.  **What is Logistic Regression, and how does it differ from Linear Regression?**\n",
        "\n",
        "    Logistic Regression is a statistical method used for binary classification problems, predicting the probability that an instance belongs to a particular class. It differs from Linear Regression in that it predicts a probability (a value between 0 and 1) by applying a sigmoid function to the linear combination of input features, whereas Linear Regression predicts a continuous output value.\n",
        "\n",
        "2.  **What is the mathematical equation of Logistic Regression?**\n",
        "\n",
        "    The core of Logistic Regression is the linear combination of features:\n",
        "    $z = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$\n",
        "    The probability of the instance belonging to the positive class is then given by the sigmoid function:\n",
        "    $P(Y=1|X) = \\frac{1}{1 + e^{-z}}$\n",
        "\n",
        "3.  **Why do we use the Sigmoid function in Logistic Regression?**\n",
        "\n",
        "    The Sigmoid function (also known as the logistic function) is used because it maps any real-valued input to a value between 0 and 1. This is essential for Logistic Regression as we want to predict probabilities. The sigmoid function has a characteristic \"S\" shape, which makes it suitable for modeling the probability of a binary outcome.\n",
        "\n",
        "4.  **What is the cost function of Logistic Regression?**\n",
        "\n",
        "    The most common cost function for Logistic Regression is the Binary Cross-Entropy (or Log Loss) function. For a single training example, the cost is:\n",
        "    $Cost(y, \\hat{y}) = -[y \\log(\\hat{y}) + (1-y) \\log(1-\\hat{y})]$\n",
        "    Where $y$ is the true label (0 or 1) and $\\hat{y}$ is the predicted probability. The overall cost function for the training set is the average of the costs for all training examples.\n",
        "\n",
        "5.  **What is Regularization in Logistic Regression? Why is it needed?**\n",
        "\n",
        "    Regularization is a technique used to prevent overfitting in Logistic Regression by adding a penalty term to the cost function. It discourages the model from assigning excessively large weights to features, which can happen when the model becomes too complex and starts to fit the noise in the training data. Regularization helps to improve the model's generalization performance on unseen data.\n",
        "\n",
        "6.  **Explain the difference between Lasso, Ridge, and Elastic Net regression.**\n",
        "\n",
        "    These are different types of regularization techniques:\n",
        "    *   **Ridge Regression (L2 regularization):** Adds a penalty proportional to the square of the magnitude of the coefficients ($\\sum \\beta_i^2$). It shrinks the coefficients towards zero but rarely makes them exactly zero.\n",
        "    *   **Lasso Regression (L1 regularization):** Adds a penalty proportional to the absolute value of the magnitude of the coefficients ($\\sum |\\beta_i|$). It can shrink some coefficients exactly to zero, effectively performing feature selection.\n",
        "    *   **Elastic Net Regression:** Combines both L1 and L2 penalties. It encourages sparsity like Lasso and also handles correlated features well like Ridge.\n",
        "\n",
        "7.  **When should we use Elastic Net instead of Lasso or Ridge?**\n",
        "\n",
        "    Elastic Net is often preferred over Lasso or Ridge when:\n",
        "    *   There are highly correlated features. Ridge handles correlated features better than Lasso, and Elastic Net benefits from this.\n",
        "    *   You want to perform feature selection (like Lasso) but also handle the situation where multiple correlated features are important (where Lasso might arbitrarily select only one).\n",
        "\n",
        "8.  **What is the impact of the regularization parameter (Î») in Logistic Regression?**\n",
        "\n",
        "    The regularization parameter ($\\lambda$ or alpha in some libraries) controls the strength of the regularization penalty.\n",
        "    *   A large $\\lambda$ imposes a strong penalty, shrinking coefficients more aggressively towards zero. This can lead to a simpler model and potentially underfitting if $\\lambda$ is too large.\n",
        "    *   A small $\\lambda$ imposes a weak penalty, allowing coefficients to be larger. This can lead to a more complex model and potentially overfitting if $\\lambda$ is too small.\n",
        "    Choosing the optimal $\\lambda$ is crucial and is typically done through techniques like cross-validation.\n",
        "\n",
        "9.  **What are the key assumptions of Logistic Regression?**\n",
        "\n",
        "    While Logistic Regression has fewer strict assumptions than Linear Regression, some key considerations include:\n",
        "    *   **Binary outcome:** Logistic Regression is designed for binary classification (two classes).\n",
        "    *   **Linearity of the log-odds:** It assumes a linear relationship between the independent variables and the log-odds of the outcome.\n",
        "    *   **Independence of observations:** The observations are assumed to be independent of each other.\n",
        "    *   **Absence of multicollinearity:** While not a strict assumption, high multicollinearity among independent variables can make coefficient interpretation difficult and affect model stability.\n",
        "\n",
        "10. **What are some alternatives to Logistic Regression for classification tasks?**\n",
        "\n",
        "    Several alternatives exist, including:\n",
        "    *   Support Vector Machines (SVM)\n",
        "    *   Decision Trees\n",
        "    *   Random Forests\n",
        "    *   Gradient Boosting Machines (e.g., XGBoost, LightGBM)\n",
        "    *   K-Nearest Neighbors (KNN)\n",
        "    *   Naive Bayes\n",
        "    *   Neural Networks\n",
        "\n",
        "11. **What are Classification Evaluation Metrics?**\n",
        "\n",
        "    Classification evaluation metrics are used to assess the performance of a classification model. Common metrics include:\n",
        "    *   **Accuracy:** The proportion of correctly classified instances.\n",
        "    *   **Precision:** The proportion of true positive predictions among all positive predictions.\n",
        "    *   **Recall (Sensitivity):** The proportion of true positive predictions among all actual positive instances.\n",
        "    *   **F1-Score:** The harmonic mean of precision and recall, providing a balance between the two.\n",
        "    *   **AUC (Area Under the ROC Curve):** Measures the model's ability to distinguish between positive and negative classes across different probability thresholds.\n",
        "    *   **Log Loss (Binary Cross-Entropy):** A measure of the prediction error, penalizing confident incorrect predictions more heavily.\n",
        "\n",
        "12. **How does class imbalance affect Logistic Regression?**\n",
        "\n",
        "    Class imbalance occurs when the number of instances in one class is significantly lower than in the other. This can negatively affect Logistic Regression by:\n",
        "    *   **Biasing the model:** The model may be biased towards the majority class, leading to poor performance on the minority class.\n",
        "    *   **Misleading accuracy:** High accuracy can be achieved by simply predicting the majority class, even if the model is not effectively identifying the minority class.\n",
        "    Techniques to address class imbalance include oversampling the minority class, undersampling the majority class, using different evaluation metrics, or employing algorithms more robust to imbalance.\n",
        "\n",
        "13. **What is Hyperparameter Tuning in Logistic Regression?**\n",
        "\n",
        "    Hyperparameter tuning is the process of finding the optimal values for the hyperparameters of a Logistic Regression model (or any machine learning model) to maximize its performance. Hyperparameters are settings that are not learned from the data but are set before training. For Logistic Regression, common hyperparameters include the regularization parameter (C or $\\lambda$), the type of penalty (L1, L2, Elastic Net), and the solver.\n",
        "\n",
        "14. **What are different solvers in Logistic Regression? Which one should be used?**\n",
        "\n",
        "    Solvers are algorithms used to optimize the cost function and find the model's coefficients during training. Common solvers in libraries like scikit-learn include:\n",
        "    *   **liblinear:** Good for small datasets and L1/L2 regularization.\n",
        "    *   **newton-cg, lbfgs, sag, saga:** Suitable for larger datasets. `lbfgs` is often the default and a good general-purpose choice. `saga` is a good option for L1 regularization on larger datasets.\n",
        "    The best solver to use depends on the dataset size, the type of regularization, and computational resources. It's often recommended to try different solvers or use the default and see which one performs best.\n",
        "\n",
        "15. **How is Logistic Regression extended for multiclass classification?**\n",
        "\n",
        "    Logistic Regression can be extended for multiclass classification using strategies like:\n",
        "    *   **One-vs-Rest (OvR) or One-vs-All (OvA):** Trains a separate binary Logistic Regression model for each class, where each model distinguishes one class from all the others.\n",
        "    *   **Softmax Regression (Multinomial Logistic Regression):** A direct extension that models the probability of an instance belonging to each class simultaneously using the softmax function.\n",
        "\n",
        "16. **What are the advantages and disadvantages of Logistic Regression?**\n",
        "\n",
        "    **Advantages:**\n",
        "    *   Simple and easy to understand and implement.\n",
        "    *   Computationally efficient, especially for large datasets.\n",
        "    *   Provides probability scores, which can be useful for decision-making.\n",
        "    *   Coefficients can be interpreted to understand the impact of features on the outcome (with caution, especially with regularization).\n",
        "    *   Less prone to overfitting than complex models if regularization is applied.\n",
        "\n",
        "    **Disadvantages:**\n",
        "    *   Assumes a linear relationship between the features and the log-odds, which may not always hold.\n",
        "    *   Can struggle with complex non-linear relationships.\n",
        "    *   May perform poorly when there are many features or highly correlated features (without regularization).\n",
        "    *   Sensitive to outliers.\n",
        "\n",
        "17. **What are some use cases of Logistic Regression?**\n",
        "\n",
        "    Logistic Regression is widely used in various fields, including:\n",
        "    *   **Spam detection:** Classifying emails as spam or not spam.\n",
        "    *   **Medical diagnosis:** Predicting the probability of a disease based on symptoms and patient data.\n",
        "    *   **Credit risk assessment:** Predicting the likelihood of a loan applicant defaulting.\n",
        "    *   **Marketing:** Predicting whether a customer will click on an ad or purchase a product.\n",
        "    *   **Sentiment analysis:** Classifying text as positive or negative sentiment.\n",
        "\n",
        "18. **What is the difference between Softmax Regression and Logistic Regression?**\n",
        "\n",
        "    Logistic Regression is specifically for binary classification (two classes), while Softmax Regression (Multinomial Logistic Regression) is for multiclass classification (more than two classes). Softmax Regression extends the concept of Logistic Regression by calculating probabilities for each class using the softmax function, ensuring that the probabilities for all classes sum up to 1.\n",
        "\n",
        "19. **How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**\n",
        "\n",
        "    The choice between OvR and Softmax can depend on the problem and the library being used.\n",
        "    *   **Softmax** is often preferred when the classes are mutually exclusive (an instance belongs to only one class). It provides a more natural probabilistic interpretation for multiclass problems.\n",
        "    *   **OvR** can be useful when instances can belong to multiple classes (though this is less common in standard classification) or when using algorithms that are inherently binary. In practice, for many standard multiclass problems, Softmax is a good default choice. Some libraries might use OvR as the default for certain algorithms.\n",
        "\n",
        "20. **How do we interpret coefficients in Logistic Regression?**\n",
        "\n",
        "    The coefficients ($\\beta_i$) in Logistic Regression represent the change in the log-odds of the outcome for a one-unit increase in the corresponding feature ($x_i$), assuming all other features are held constant.\n",
        "    *   A positive coefficient indicates that as the feature increases, the log-odds of the positive class increase (and thus the probability of the positive class increases).\n",
        "    *   A negative coefficient indicates that as the feature increases, the log-odds of the positive class decrease (and thus the probability of the positive class decreases).\n",
        "    Interpreting the direct impact on the probability is more complex due to the sigmoid function, but the sign of the coefficient indicates the direction of the relationship. It's important to interpret coefficients with caution, especially in the presence of interactions, non-linearities, or regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical"
      ],
      "metadata": {
        "id": "SRJtIpQsGGHT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UDzZoLyqGCj9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ce79928"
      },
      "source": [
        "Here are the Python programs for the practical Logistic Regression tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4049f50e"
      },
      "source": [
        "1.  **Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa130f52",
        "outputId": "0a66cff0-343d-4328-f66b-d0eaeed61317"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load a sample dataset (Iris dataset)\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# For binary classification, let's use only two classes (0 and 1)\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03217943"
      },
      "source": [
        "2.  **Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38802998",
        "outputId": "e9b283cc-767a-4b9f-e515-d980ac449659"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer # Using a dataset where L1 might be more relevant\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with L1 regularization\n",
        "# 'liblinear' solver supports L1 penalty\n",
        "model_l1 = LogisticRegression(penalty='l1', solver='liblinear', random_state=42)\n",
        "model_l1.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_l1 = model_l1.predict(X_test)\n",
        "\n",
        "# Print the model accuracy\n",
        "accuracy_l1 = accuracy_score(y_test, y_pred_l1)\n",
        "print(f\"Model Accuracy with L1 Regularization: {accuracy_l1:.4f}\")\n",
        "\n",
        "# Print coefficients (note: some might be zero due to L1)\n",
        "print(\"\\nModel Coefficients with L1 Regularization:\")\n",
        "for i, coef in enumerate(model_l1.coef_[0]):\n",
        "    print(f\"Feature {i}: {coef:.4f}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 0.9649\n",
            "\n",
            "Model Coefficients with L1 Regularization:\n",
            "Feature 0: 4.1745\n",
            "Feature 1: 0.1504\n",
            "Feature 2: -0.2902\n",
            "Feature 3: -0.0153\n",
            "Feature 4: 0.0000\n",
            "Feature 5: 0.0000\n",
            "Feature 6: 0.0000\n",
            "Feature 7: 0.0000\n",
            "Feature 8: 0.0000\n",
            "Feature 9: 0.0000\n",
            "Feature 10: 0.0000\n",
            "Feature 11: 1.8394\n",
            "Feature 12: 0.0000\n",
            "Feature 13: -0.1119\n",
            "Feature 14: 0.0000\n",
            "Feature 15: 0.0000\n",
            "Feature 16: 0.0000\n",
            "Feature 17: 0.0000\n",
            "Feature 18: 0.0000\n",
            "Feature 19: 0.0000\n",
            "Feature 20: 0.0000\n",
            "Feature 21: -0.4274\n",
            "Feature 22: 0.0000\n",
            "Feature 23: -0.0141\n",
            "Feature 24: 0.0000\n",
            "Feature 25: 0.0000\n",
            "Feature 26: -4.2093\n",
            "Feature 27: 0.0000\n",
            "Feature 28: 0.0000\n",
            "Feature 29: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0fcb88f"
      },
      "source": [
        "3.  **Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da6421d0",
        "outputId": "04a4d6f3-db13-408e-e57d-3ba843abad99"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# from sklearn.datasets import load_boston # Using a dataset (for demonstration, though Boston is regression)\n",
        "# Let's switch back to a classification dataset for consistency\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with L2 regularization\n",
        "model_l2 = LogisticRegression(penalty='l2', solver='liblinear', random_state=42)\n",
        "model_l2.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_l2 = model_l2.predict(X_test)\n",
        "\n",
        "# Print the model accuracy\n",
        "accuracy_l2 = accuracy_score(y_test, y_pred_l2)\n",
        "print(f\"Model Accuracy with L2 Regularization: {accuracy_l2:.4f}\")\n",
        "\n",
        "# Print coefficients\n",
        "print(\"\\nModel Coefficients with L2 Regularization:\")\n",
        "for i, coef in enumerate(model_l2.coef_[0]):\n",
        "    print(f\"Feature {i}: {coef:.4f}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization: 0.9649\n",
            "\n",
            "Model Coefficients with L2 Regularization:\n",
            "Feature 0: 2.1753\n",
            "Feature 1: 0.1597\n",
            "Feature 2: -0.1254\n",
            "Feature 3: -0.0040\n",
            "Feature 4: -0.1304\n",
            "Feature 5: -0.4113\n",
            "Feature 6: -0.6550\n",
            "Feature 7: -0.3501\n",
            "Feature 8: -0.2022\n",
            "Feature 9: -0.0293\n",
            "Feature 10: -0.0661\n",
            "Feature 11: 1.4036\n",
            "Feature 12: 0.1179\n",
            "Feature 13: -0.1093\n",
            "Feature 14: -0.0146\n",
            "Feature 15: -0.0248\n",
            "Feature 16: -0.0635\n",
            "Feature 17: -0.0411\n",
            "Feature 18: -0.0488\n",
            "Feature 19: -0.0008\n",
            "Feature 20: 1.1552\n",
            "Feature 21: -0.3903\n",
            "Feature 22: -0.0768\n",
            "Feature 23: -0.0213\n",
            "Feature 24: -0.2421\n",
            "Feature 25: -1.1398\n",
            "Feature 26: -1.5793\n",
            "Feature 27: -0.6174\n",
            "Feature 28: -0.7291\n",
            "Feature 29: -0.1108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "668179d4"
      },
      "source": [
        "4.  **Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9bb7571",
        "outputId": "1e0ab050-884c-4ca3-b5dd-94ac11716c97"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with Elastic Net regularization\n",
        "# 'saga' solver supports Elastic Net\n",
        "# l1_ratio controls the mix of L1 and L2 (0 for L2, 1 for L1)\n",
        "model_elasticnet = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, random_state=42)\n",
        "model_elasticnet.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_elasticnet = model_elasticnet.predict(X_test)\n",
        "\n",
        "# Print the model accuracy\n",
        "accuracy_elasticnet = accuracy_score(y_test, y_pred_elasticnet)\n",
        "print(f\"Model Accuracy with Elastic Net Regularization: {accuracy_elasticnet:.4f}\")\n",
        "\n",
        "# Print coefficients\n",
        "print(\"\\nModel Coefficients with Elastic Net Regularization:\")\n",
        "for i, coef in enumerate(model_elasticnet.coef_[0]):\n",
        "    print(f\"Feature {i}: {coef:.4f}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 0.9532\n",
            "\n",
            "Model Coefficients with Elastic Net Regularization:\n",
            "Feature 0: 0.0026\n",
            "Feature 1: 0.0047\n",
            "Feature 2: 0.0155\n",
            "Feature 3: 0.0110\n",
            "Feature 4: 0.0000\n",
            "Feature 5: 0.0000\n",
            "Feature 6: -0.0000\n",
            "Feature 7: -0.0000\n",
            "Feature 8: 0.0000\n",
            "Feature 9: 0.0000\n",
            "Feature 10: 0.0000\n",
            "Feature 11: 0.0004\n",
            "Feature 12: 0.0000\n",
            "Feature 13: -0.0060\n",
            "Feature 14: 0.0000\n",
            "Feature 15: 0.0000\n",
            "Feature 16: 0.0000\n",
            "Feature 17: 0.0000\n",
            "Feature 18: 0.0000\n",
            "Feature 19: 0.0000\n",
            "Feature 20: 0.0026\n",
            "Feature 21: 0.0059\n",
            "Feature 22: 0.0154\n",
            "Feature 23: -0.0121\n",
            "Feature 24: 0.0000\n",
            "Feature 25: -0.0000\n",
            "Feature 26: -0.0000\n",
            "Feature 27: -0.0000\n",
            "Feature 28: 0.0001\n",
            "Feature 29: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfbcb2fe"
      },
      "source": [
        "5.  **Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7968ab69",
        "outputId": "e2830bb5-e370-4605-d3d0-140ca8ab93b9"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load a sample dataset (Iris dataset) - this is a multiclass dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression for multiclass classification using 'ovr' strategy\n",
        "# 'liblinear' solver only supports 'ovr' for multiclass\n",
        "model_ovr = LogisticRegression(multi_class='ovr', solver='liblinear', random_state=42)\n",
        "model_ovr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_ovr = model_ovr.predict(X_test)\n",
        "\n",
        "# Print the model accuracy\n",
        "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
        "print(f\"Multiclass Model Accuracy (OvR): {accuracy_ovr:.4f}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Model Accuracy (OvR): 0.9778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88ddcfdc"
      },
      "source": [
        "6.  **Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ce137f",
        "outputId": "7bee03f7-bfa0-4e9f-c196-2d724783e3c4"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the parameter grid to search\n",
        "# Note: Not all penalties work with all solvers.\n",
        "# For simplicity, let's use 'liblinear' which supports 'l1' and 'l2'.\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "\n",
        "# Apply GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters found by GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "print(\"\\nBest Cross-Validation Accuracy found by GridSearchCV:\")\n",
        "print(f\"{grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nTest Set Accuracy with Best Model: {test_accuracy:.4f}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters found by GridSearchCV:\n",
            "{'C': 100, 'penalty': 'l1'}\n",
            "\n",
            "Best Cross-Validation Accuracy found by GridSearchCV:\n",
            "0.9673\n",
            "\n",
            "Test Set Accuracy with Best Model: 0.9766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6eaf517"
      },
      "source": [
        "7.  **Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a7c9877",
        "outputId": "5a4dba79-d69f-4748-8081-4c88ce5fc6a1"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "\n",
        "# Apply Stratified K-Fold Cross-Validation\n",
        "# StratifiedKFold ensures that each fold has the same proportion of observations\n",
        "# of the target variable as the original dataset.\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get cross-validation scores\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Print the scores for each fold\n",
        "print(\"Accuracy for each fold:\", [f\"{score:.4f}\" for score in scores])\n",
        "\n",
        "# Print the average accuracy\n",
        "print(f\"\\nAverage Cross-Validation Accuracy: {scores.mean():.4f}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each fold: ['0.9474', '0.9211', '0.9561', '0.9649', '0.9646']\n",
            "\n",
            "Average Cross-Validation Accuracy: 0.9508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4a80ffb"
      },
      "source": [
        "8.  **Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b91f9da2",
        "outputId": "30c49092-560c-48b9-8b9b-eb24562b4e29"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification # Generate a synthetic dataset for demonstration\n",
        "\n",
        "# Generate a synthetic dataset and save it to a CSV\n",
        "X, y = make_classification(n_samples=200, n_features=20, random_state=42)\n",
        "df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
        "df['target'] = y\n",
        "csv_filename = 'synthetic_data.csv'\n",
        "df.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"Synthetic dataset saved to {csv_filename}\")\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "try:\n",
        "    data = pd.read_csv(csv_filename)\n",
        "\n",
        "    # Separate features (X) and target (y)\n",
        "    X = data.drop('target', axis=1)\n",
        "    y = data['target']\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Apply Logistic Regression\n",
        "    model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Print the model accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nModel Accuracy after loading from CSV: {accuracy:.4f}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{csv_filename}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic dataset saved to synthetic_data.csv\n",
            "\n",
            "Model Accuracy after loading from CSV: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7215b62"
      },
      "source": [
        "Here are more Python programs for practical Logistic Regression tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "820b16da"
      },
      "source": [
        "9. **Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1752555",
        "outputId": "15769180-9a94-4815-f096-9418c064a4e0"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the parameter distribution to sample from\n",
        "# Note: Ensure compatibility between penalty and solver\n",
        "param_dist = {\n",
        "    'C': uniform(loc=0, scale=10), # Continuous distribution for C\n",
        "    'penalty': ['l1', 'l2'], # Categorical for penalty\n",
        "    'solver': ['liblinear', 'saga'] # Solvers that support l1 and l2\n",
        "}\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Apply RandomizedSearchCV\n",
        "# n_iter: Number of parameter settings that are sampled.\n",
        "# cv: number of folds for cross-validation\n",
        "# scoring: evaluation metric\n",
        "# random_state: for reproducibility\n",
        "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters found by RandomizedSearchCV:\")\n",
        "print(random_search.best_params_)\n",
        "\n",
        "print(\"\\nBest Cross-Validation Accuracy found by RandomizedSearchCV:\")\n",
        "print(f\"{random_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nTest Set Accuracy with Best Model: {test_accuracy:.4f}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters found by RandomizedSearchCV:\n",
            "{'C': np.float64(7.319939418114051), 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "\n",
            "Best Cross-Validation Accuracy found by RandomizedSearchCV:\n",
            "0.9622\n",
            "\n",
            "Test Set Accuracy with Best Model: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "257dec94"
      },
      "source": [
        "10. **Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faa5ce6a",
        "outputId": "bb5c95fb-eef3-4d2b-f9cf-d05cbb0e4cd9"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris # Multiclass dataset\n",
        "\n",
        "# Load a sample multiclass dataset (Iris dataset)\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression base model\n",
        "base_model = LogisticRegression(solver='liblinear', random_state=42) # liblinear supports binary\n",
        "\n",
        "# Apply One-vs-One strategy for multiclass classification\n",
        "# This trains a separate binary classifier for each pair of classes.\n",
        "model_ovo = OneVsOneClassifier(base_model)\n",
        "model_ovo.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_ovo = model_ovo.predict(X_test)\n",
        "\n",
        "# Print the model accuracy\n",
        "accuracy_ovo = accuracy_score(y_test, y_pred_ovo)\n",
        "print(f\"Multiclass Model Accuracy (OvO): {accuracy_ovo:.4f}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Model Accuracy (OvO): 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b78b6d2"
      },
      "source": [
        "11. **Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "2a5dc37d",
        "outputId": "ae3dd2b5-92a7-418c-d360-55fe0316a6b5"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer # Binary classification dataset\n",
        "\n",
        "# Load a sample binary dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=cancer.target_names, yticklabels=cancer.target_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - Logistic Regression')\n",
        "plt.show()\n",
        "\n",
        "# Print accuracy for context\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.4f}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 59   4]\n",
            " [  2 106]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c9fa573"
      },
      "source": [
        "12. **Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5c2c374",
        "outputId": "47ae81df-0170-4ba2-829d-9687c48e067b"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer # Binary classification dataset\n",
        "\n",
        "# Load a sample binary dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Model Precision: {precision:.4f}\")\n",
        "print(f\"Model Recall: {recall:.4f}\")\n",
        "print(f\"Model F1-Score: {f1:.4f}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9649\n",
            "Model Precision: 0.9636\n",
            "Model Recall: 0.9815\n",
            "Model F1-Score: 0.9725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02213af1"
      },
      "source": [
        "13. **Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54bb6390",
        "outputId": "b0e44b64-5341-4dd5-a89f-a8951a56ae8c"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate an imbalanced synthetic dataset\n",
        "# n_classes=2, weights=[0.9, 0.1] creates a dataset with 90% class 0 and 10% class 1\n",
        "X, y = make_classification(n_samples=1000, n_features=20, weights=[0.9, 0.1], random_state=42, n_informative=15)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Class distribution in training data:\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "\n",
        "# Train Logistic Regression WITHOUT class weights\n",
        "model_no_weights = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model_no_weights.fit(X_train, y_train)\n",
        "y_pred_no_weights = model_no_weights.predict(X_test)\n",
        "\n",
        "print(\"\\n--- Model without Class Weights ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_no_weights):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_no_weights))\n",
        "\n",
        "# Train Logistic Regression WITH class weights\n",
        "# class_weight='balanced' automatically adjusts weights inversely proportional\n",
        "# to class frequencies in the training data.\n",
        "model_with_weights = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42)\n",
        "model_with_weights.fit(X_train, y_train)\n",
        "y_pred_with_weights = model_with_weights.predict(X_test)\n",
        "\n",
        "print(\"\\n--- Model with Class Weights ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_with_weights):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_with_weights))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in training data:\n",
            "0    623\n",
            "1     77\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Model without Class Weights ---\n",
            "Accuracy: 0.9200\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96       276\n",
            "           1       0.50      0.46      0.48        24\n",
            "\n",
            "    accuracy                           0.92       300\n",
            "   macro avg       0.73      0.71      0.72       300\n",
            "weighted avg       0.92      0.92      0.92       300\n",
            "\n",
            "\n",
            "--- Model with Class Weights ---\n",
            "Accuracy: 0.7833\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.79      0.87       276\n",
            "           1       0.23      0.75      0.36        24\n",
            "\n",
            "    accuracy                           0.78       300\n",
            "   macro avg       0.60      0.77      0.61       300\n",
            "weighted avg       0.91      0.78      0.83       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aa212b9"
      },
      "source": [
        "14. **Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2e792e5",
        "outputId": "9accd75d-11b7-4d06-952d-6342050fae15"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import fetch_openml # To fetch Titanic dataset\n",
        "\n",
        "# Fetch the Titanic dataset\n",
        "# 'titanic' is the dataset name on OpenML\n",
        "# version=1 specifies a particular version\n",
        "# as_frame=True returns a pandas DataFrame\n",
        "try:\n",
        "    titanic = fetch_openml('titanic', version=1, as_frame=True)\n",
        "    X = titanic.data\n",
        "    y = titanic.target\n",
        "\n",
        "    # Convert target to numeric (0 or 1)\n",
        "    y = y.astype(int)\n",
        "\n",
        "    # Select relevant features (excluding 'name', 'ticket', 'home.dest' as they need more complex handling)\n",
        "    features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "    X = X[features]\n",
        "\n",
        "    # Define preprocessing steps\n",
        "    # Impute missing values for numerical and categorical features\n",
        "    # One-hot encode categorical features\n",
        "    numerical_features = ['age', 'fare']\n",
        "    categorical_features = ['pclass', 'sex', 'sibsp', 'parch', 'embarked'] # pclass is treated as categorical here\n",
        "\n",
        "    numerical_transformer = SimpleImputer(strategy='mean')\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # Create a column transformer to apply different transformations to different columns\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "\n",
        "    # Create a Logistic Regression model pipeline\n",
        "    # This pipeline first preprocesses the data and then trains the Logistic Regression model\n",
        "    model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                     ('classifier', LogisticRegression(solver='liblinear', random_state=42))])\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    # Use stratify to maintain the proportion of 'survived' in train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "    # Train the model\n",
        "    model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model_pipeline.predict(X_test)\n",
        "\n",
        "    # Evaluate performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Model Accuracy on Titanic Dataset: {accuracy:.4f}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while fetching or processing the Titanic dataset: {e}\")\n",
        "    print(\"Please ensure you have internet access and the 'openml' library installed (`pip install openml`).\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy on Titanic Dataset: 0.8117\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       243\n",
            "           1       0.77      0.73      0.75       150\n",
            "\n",
            "    accuracy                           0.81       393\n",
            "   macro avg       0.80      0.80      0.80       393\n",
            "weighted avg       0.81      0.81      0.81       393\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7000695b"
      },
      "source": [
        "15. **Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ecc31db",
        "outputId": "6548f8ee-069c-4f52-fe46-36ed234e0fd4"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import load_breast_cancer # Dataset where scaling can be beneficial\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- Model WITHOUT Scaling ---\n",
        "model_no_scale = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model_no_scale.fit(X_train, y_train)\n",
        "y_pred_no_scale = model_no_scale.predict(X_test)\n",
        "accuracy_no_scale = accuracy_score(y_test, y_pred_no_scale)\n",
        "print(f\"Model Accuracy WITHOUT Scaling: {accuracy_no_scale:.4f}\")\n",
        "\n",
        "# --- Model WITH Scaling ---\n",
        "# Create a pipeline that first scales the data and then applies Logistic Regression\n",
        "model_with_scale = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('logistic', LogisticRegression(solver='liblinear', random_state=42))\n",
        "])\n",
        "\n",
        "model_with_scale.fit(X_train, y_train)\n",
        "y_pred_with_scale = model_with_scale.predict(X_test)\n",
        "accuracy_with_scale = accuracy_score(y_test, y_pred_with_scale)\n",
        "print(f\"Model Accuracy WITH Scaling (StandardScaler): {accuracy_with_scale:.4f}\")\n",
        "\n",
        "# Compare the results\n",
        "print(\"\\nComparison:\")\n",
        "print(f\"Accuracy difference (With Scaling - Without Scaling): {accuracy_with_scale - accuracy_no_scale:.4f}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy WITHOUT Scaling: 0.9649\n",
            "Model Accuracy WITH Scaling (StandardScaler): 0.9825\n",
            "\n",
            "Comparison:\n",
            "Accuracy difference (With Scaling - Without Scaling): 0.0175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd91ac2f"
      },
      "source": [
        "16. **Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "20ce5f8d",
        "outputId": "4e8be52c-3dad-4d83-98d5-671042119a43"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer # Binary classification dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
        "\n",
        "\n",
        "# Load a sample binary dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with scaling and lbfgs solver\n",
        "# Need predict_proba for the curve\n",
        "model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('logistic', LogisticRegression(solver='lbfgs', random_state=42, max_iter=10000)) # Increased max_iter\n",
        "])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class (class 1)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "# Optional: Plot ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Also print accuracy for comparison\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.4f}\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9979\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy: 0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "734d3303"
      },
      "source": [
        "17. **Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0f281e2",
        "outputId": "070f3ab8-22f3-4dc2-f38c-31807c521f00"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer # Binary classification dataset\n",
        "\n",
        "# Load a sample binary dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with a custom C value\n",
        "# C is the inverse of regularization strength; smaller C means stronger regularization.\n",
        "custom_c = 0.5\n",
        "model_custom_c = LogisticRegression(C=custom_c, solver='liblinear', random_state=42)\n",
        "model_custom_c.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_custom_c = model_custom_c.predict(X_test)\n",
        "\n",
        "# Print the model accuracy\n",
        "accuracy_custom_c = accuracy_score(y_test, y_pred_custom_c)\n",
        "print(f\"Model Accuracy with C={custom_c}: {accuracy_custom_c:.4f}\")\n",
        "\n",
        "# For comparison, train with default C (usually 1.0)\n",
        "model_default_c = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model_default_c.fit(X_train, y_train)\n",
        "y_pred_default_c = model_default_c.predict(X_test)\n",
        "accuracy_default_c = accuracy_score(y_test, y_pred_default_c)\n",
        "print(f\"Model Accuracy with Default C (usually 1.0): {accuracy_default_c:.4f}\")\n",
        "\n",
        "# Note: The term \"learning rate\" is typically associated with optimization algorithms\n",
        "# like Gradient Descent. In scikit-learn's Logistic Regression, `C` controls\n",
        "# regularization strength, which indirectly affects how the model learns, but\n",
        "# it's not a step size like a learning rate in gradient descent."
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with C=0.5: 0.9649\n",
            "Model Accuracy with Default C (usually 1.0): 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcff989f"
      },
      "source": [
        "18. **Write a Python program to train Logistic Regression and identify important features based on model coefficients.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d805e3a",
        "outputId": "95c190ea-ce56-4884-83bf-d896e0079e8d"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer # Dataset with meaningful features\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "feature_names = cancer.feature_names # Get feature names from the dataset\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression (using a solver compatible with examining coefficients)\n",
        "# 'liblinear' is good for this and handles L1/L2.\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get the coefficients\n",
        "# For binary classification, coef_ is of shape (1, n_features)\n",
        "coefficients = model.coef_[0]\n",
        "\n",
        "# Create a DataFrame to easily view features and their coefficients\n",
        "coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
        "\n",
        "# Sort features by the absolute value of their coefficients to see the most influential ones\n",
        "coef_df['Abs_Coefficient'] = abs(coef_df['Coefficient'])\n",
        "sorted_coef_df = coef_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
        "\n",
        "# Print the sorted coefficients\n",
        "print(\"Important Features based on Absolute Model Coefficients:\")\n",
        "print(sorted_coef_df[['Feature', 'Coefficient']])\n",
        "\n",
        "# Note: Interpretation of coefficients should be done carefully, especially with\n",
        "# correlated features or if features are not on the same scale (consider scaling).\n",
        "# The sign of the coefficient indicates the direction of the relationship with\n",
        "# the log-odds of the positive class."
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Important Features based on Absolute Model Coefficients:\n",
            "                    Feature  Coefficient\n",
            "0               mean radius     2.175329\n",
            "26          worst concavity    -1.579345\n",
            "11            texture error     1.403643\n",
            "20             worst radius     1.155193\n",
            "25        worst compactness    -1.139760\n",
            "28           worst symmetry    -0.729143\n",
            "6            mean concavity    -0.655026\n",
            "27     worst concave points    -0.617351\n",
            "5          mean compactness    -0.411271\n",
            "21            worst texture    -0.390328\n",
            "7       mean concave points    -0.350106\n",
            "24         worst smoothness    -0.242144\n",
            "8             mean symmetry    -0.202222\n",
            "1              mean texture     0.159658\n",
            "4           mean smoothness    -0.130413\n",
            "2            mean perimeter    -0.125372\n",
            "12          perimeter error     0.117866\n",
            "29  worst fractal dimension    -0.110785\n",
            "13               area error    -0.109265\n",
            "22          worst perimeter    -0.076792\n",
            "10             radius error    -0.066118\n",
            "16          concavity error    -0.063487\n",
            "18           symmetry error    -0.048783\n",
            "17     concave points error    -0.041148\n",
            "9    mean fractal dimension    -0.029289\n",
            "15        compactness error    -0.024838\n",
            "23               worst area    -0.021324\n",
            "14         smoothness error    -0.014646\n",
            "3                 mean area    -0.004002\n",
            "19  fractal dimension error    -0.000769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51b75c04"
      },
      "source": [
        "Here are more Python programs for practical Logistic Regression tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "183e6100"
      },
      "source": [
        "19. **Write a Python program to train Logistic Regression and evaluate its performance using Cohenâs Kappa Score.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f5be204",
        "outputId": "d9cfb147-7ed0-46cd-919c-fdcb73bb861e"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer # Binary classification dataset\n",
        "\n",
        "# Load a sample binary dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Cohen's Kappa Score\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Print the score\n",
        "print(f\"Model Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Cohen's Kappa Score: {kappa:.4f}\")\n",
        "\n",
        "# Note: Kappa score measures the agreement between two raters (in this case,\n",
        "# the model and the true labels) beyond what would be expected by chance.\n",
        "# A score of 1 indicates perfect agreement, 0 indicates agreement equivalent\n",
        "# to random chance, and negative scores indicate agreement less than chance."
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9649\n",
            "Cohen's Kappa Score: 0.9241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a3a699f"
      },
      "source": [
        "20. **Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "2cca38f9",
        "outputId": "eae42e1e-4d9a-48e0-9a45-ed61c992f6d1"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, auc, average_precision_score\n",
        "from sklearn.datasets import load_breast_cancer # Binary classification dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# Load a sample binary dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with scaling and lbfgs solver\n",
        "# Need predict_proba for the curve\n",
        "model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('logistic', LogisticRegression(solver='lbfgs', random_state=42))\n",
        "])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class (class 1)\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate Precision-Recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Calculate Area Under the Precision-Recall Curve (AUPRC)\n",
        "auprc = auc(recall, precision)\n",
        "average_precision = average_precision_score(y_test, y_scores) # Alternative calculation\n",
        "\n",
        "print(f\"Area Under the Precision-Recall Curve (AUPRC): {auprc:.4f}\")\n",
        "print(f\"Average Precision Score: {average_precision:.4f}\")\n",
        "\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='darkorange', lw=2, label=f'Precision-Recall curve (area = {auprc:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve - Logistic Regression')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area Under the Precision-Recall Curve (AUPRC): 0.9988\n",
            "Average Precision Score: 0.9988\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05f18872"
      },
      "source": [
        "21. **Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a68346b3",
        "outputId": "d6c5d04a-ed1c-43c3-83f2-48dbddc7b38a"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning) # Ignore specific warnings\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define different solvers to test\n",
        "solvers = ['liblinear', 'lbfgs', 'saga'] # Common solvers supporting L2\n",
        "\n",
        "# Train and evaluate models with different solvers\n",
        "results = {}\n",
        "for solver in solvers:\n",
        "    try:\n",
        "        # Note: saga and lbfgs can benefit from scaled data for convergence\n",
        "        # For simplicity, let's use unscaled data here to show solver comparison directly,\n",
        "        # but in practice, scaling is often recommended for these solvers.\n",
        "        if solver == 'saga':\n",
        "             # saga also supports elasticnet and l1, but comparing with l2 here\n",
        "            model = LogisticRegression(solver=solver, penalty='l2', max_iter=10000, random_state=42)\n",
        "        elif solver == 'liblinear':\n",
        "             # liblinear is good for smaller datasets and supports l1/l2\n",
        "            model = LogisticRegression(solver=solver, penalty='l2', random_state=42)\n",
        "        else: # lbfgs\n",
        "             # lbfgs is the default and good for general use with L2\n",
        "            model = LogisticRegression(solver=solver, penalty='l2', max_iter=10000, random_state=42)\n",
        "\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        results[solver] = accuracy\n",
        "    except Exception as e:\n",
        "        results[solver] = f\"Error: {e}\"\n",
        "        print(f\"Error with solver '{solver}': {e}\")\n",
        "\n",
        "\n",
        "# Print the results\n",
        "print(\"Model Accuracy with Different Solvers:\")\n",
        "for solver, accuracy in results.items():\n",
        "    print(f\"Solver '{solver}': {accuracy:.4f}\" if isinstance(accuracy, float) else f\"Solver '{solver}': {accuracy}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Different Solvers:\n",
            "Solver 'liblinear': 0.9649\n",
            "Solver 'lbfgs': 0.9766\n",
            "Solver 'saga': 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fd8a2cc"
      },
      "source": [
        "22. **Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e592a95",
        "outputId": "32e6ca56-b27f-4376-fc35-2faddfed5664"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer # Binary classification dataset\n",
        "\n",
        "# Load a sample binary dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "# Print the score\n",
        "print(f\"Model Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
        "\n",
        "# Note: MCC is a measure of the quality of binary classifications.\n",
        "# A coefficient of +1 represents a perfect prediction, 0 represents no better\n",
        "# than random prediction, and -1 represents total disagreement between\n",
        "# prediction and observation. It's considered a balanced measure, even for\n",
        "# imbalanced classes."
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9649\n",
            "Matthews Correlation Coefficient (MCC): 0.9244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e11f9463"
      },
      "source": [
        "23. **Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "936342dc",
        "outputId": "f26901bf-5230-4beb-c16e-5a55379f0c9f"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import load_breast_cancer # Dataset where scaling can be beneficial\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- Model WITHOUT Scaling ---\n",
        "model_no_scale = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model_no_scale.fit(X_train, y_train)\n",
        "y_pred_no_scale = model_no_scale.predict(X_test)\n",
        "accuracy_no_scale = accuracy_score(y_test, y_pred_no_scale)\n",
        "print(f\"Model Accuracy WITHOUT Scaling: {accuracy_no_scale:.4f}\")\n",
        "\n",
        "# --- Model WITH Scaling ---\n",
        "# Create a pipeline that first scales the data and then applies Logistic Regression\n",
        "model_with_scale = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('logistic', LogisticRegression(solver='liblinear', random_state=42))\n",
        "])\n",
        "\n",
        "model_with_scale.fit(X_train, y_train)\n",
        "y_pred_with_scale = model_with_scale.predict(X_test)\n",
        "accuracy_with_scale = accuracy_score(y_test, y_pred_with_scale)\n",
        "print(f\"Model Accuracy WITH Scaling (StandardScaler): {accuracy_with_scale:.4f}\")\n",
        "\n",
        "# Compare the results\n",
        "print(\"\\nComparison:\")\n",
        "print(f\"Accuracy difference (With Scaling - Without Scaling): {accuracy_with_scale - accuracy_no_scale:.4f}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy WITHOUT Scaling: 0.9649\n",
            "Model Accuracy WITH Scaling (StandardScaler): 0.9825\n",
            "\n",
            "Comparison:\n",
            "Accuracy difference (With Scaling - Without Scaling): 0.0175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4276c0f6"
      },
      "source": [
        "24. **Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1f5d0d6",
        "outputId": "2dc794f8-a4f4-47c9-856d-8816086b3b8f"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler # Often good practice to scale when tuning C\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Scale the data (recommended when tuning C, especially with L2)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Define the parameter grid for C\n",
        "# C is the inverse of regularization strength. Smaller C means stronger regularization.\n",
        "# We'll search across a range of C values.\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Create a Logistic Regression model (using a solver compatible with L2, which is default)\n",
        "model = LogisticRegression(solver='liblinear', random_state=42) # liblinear works well for this range of C\n",
        "\n",
        "# Apply GridSearchCV to find the best C\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy') # cv=5 for 5-fold cross-validation\n",
        "grid_search.fit(X_train_scaled, y_train) # Fit on scaled training data\n",
        "\n",
        "# Print the best parameter (C) and the corresponding cross-validation score\n",
        "print(\"Best C found by GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "print(\"\\nBest Cross-Validation Accuracy for the optimal C:\")\n",
        "print(f\"{grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled) # Predict on scaled test data\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nTest Set Accuracy with Optimal C: {test_accuracy:.4f}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C found by GridSearchCV:\n",
            "{'C': 0.1}\n",
            "\n",
            "Best Cross-Validation Accuracy for the optimal C:\n",
            "0.9774\n",
            "\n",
            "Test Set Accuracy with Optimal C: 0.9942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f11b290"
      },
      "source": [
        "25. **Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3df80e7",
        "outputId": "1e82204c-b970-4b3e-b5a8-808a5465b961"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import joblib # Library for saving and loading models\n",
        "\n",
        "# Load a sample dataset (Breast Cancer dataset)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- Train the model ---\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --- Save the trained model ---\n",
        "model_filename = 'logistic_regression_model.joblib'\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"Trained model saved to {model_filename}\")\n",
        "\n",
        "# --- Load the model from the file ---\n",
        "loaded_model = joblib.load(model_filename)\n",
        "print(f\"Model loaded from {model_filename}\")\n",
        "\n",
        "# --- Make predictions using the loaded model ---\n",
        "y_pred_loaded = loaded_model.predict(X_test)\n",
        "\n",
        "# --- Evaluate the loaded model (should give the same accuracy as the original model) ---\n",
        "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
        "print(f\"\\nAccuracy using the loaded model: {accuracy_loaded:.4f}\")\n",
        "\n",
        "# Verify that predictions are the same\n",
        "# print(\"\\nPredictions from original model vs loaded model:\")\n",
        "# print(model.predict(X_test)[:5])\n",
        "# print(y_pred_loaded[:5])\n",
        "# print(\"Are predictions identical?\", (model.predict(X_test) == y_pred_loaded).all())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model saved to logistic_regression_model.joblib\n",
            "Model loaded from logistic_regression_model.joblib\n",
            "\n",
            "Accuracy using the loaded model: 0.9649\n"
          ]
        }
      ]
    }
  ]
}